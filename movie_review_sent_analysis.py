# -*- coding: utf-8 -*-
"""Movie_Review_Sent_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wWZVaaV5i89Jma_47We5MYXz3Lj04Iiq
"""

import nltk
import urllib.request
from nltk.corpus import stopwords
import re
import numpy as np
from collections import Counter
from collections import OrderedDict
from sklearn import preprocessing
import string
import pandas as pd
from google.colab import auth
from textblob import TextBlob
auth.authenticate_user()

#!pip install gspread
#!pip install textblob

from google.colab import auth
auth.authenticate_user()

import gspread
from google.auth import default
creds, _ = default()

gc = gspread.authorize(creds)

# open the spreadsheet by ID
worksheet = gc.open_by_key('1Sf4L-oGBNgc-vGh0mfrgEBw0YiZpuPJ20g3yargrlN4').sheet1

column_data = worksheet.col_values(5)[1:]

nltk.download('punkt')
nltk.download('stopwords')
from nltk.tokenize import word_tokenize

stop_words = set(stopwords.words('english'))

preprocessed_column_data = []
for text in column_data:
    text = text.lower()
    # tokenize the text
    tokens = nltk.word_tokenize(text)
    # remove stopwords
    filtered_tokens = [token for token in tokens if token not in stop_words]
    preprocessed_text = ' '.join(filtered_tokens)
    preprocessed_column_data.append(preprocessed_text)

all_tokens = []
for text in preprocessed_column_data:
    tokens = word_tokenize(text)
    all_tokens += tokens
unique_tokens = set(all_tokens)
print("Total unique tokens:", len(unique_tokens))



#print (" ")
#print (column_data[1])

column_c_values = worksheet.col_values(3)

column_c_values = [val for val in column_c_values if val.isdigit()]

# Get a list of all unique numbers in column C
unique_numbers = dict(OrderedDict.fromkeys(column_c_values))

print (unique_numbers)
print (len(unique_numbers))

#print(type(unique_numbers))
#unique_numbers["29590"] = 1
#print(unique_numbers)
html_id = worksheet.col_values(3)[1:]
#print(len(html_id))      #64720
#print(len(column_data))  #64720

def sentimentHelper(text:string):
  inputString = TextBlob(text)
  sentiment = inputString.sentiment.polarity
  return sentiment


def getScores2():
  curr_html_id = html_id[0]   #keep track of current html_id
  currReviewScore = 0         #total score of current review
  colValCounter = 0           #help go through column_data
  meanCounter = 0             #keep track of times we have added to score. use in average
  #print(curr_html_id)
  for tag in html_id:
    #html_id tag matches
    if tag == curr_html_id:
      #add sentiment value
      currReviewScore += sentimentHelper(column_data[colValCounter])
      colValCounter += 1
      meanCounter += 1
    #html_id tag doesnt match. New review
    else:
      #update unique_numbers
      unique_numbers[curr_html_id] = currReviewScore/meanCounter
      #start work on new review
      #update current html tag
      curr_html_id = tag
      currReviewScore = 0
      meanCounter = 0
      currReviewScore += sentimentHelper(column_data[colValCounter])
      colValCounter += 1
      meanCounter += 1
  unique_numbers[curr_html_id] = currReviewScore/meanCounter
#getScores()
#getScores1()
getScores2()

print(unique_numbers)
#print(len(unique_numbers))
#print(unique_numbers['5416'])

#manually testing for accuracy
#REMEMBER TO ACCOUNT FOR OFFSET IN RANGE CALCULATION
#TESTING: 5416
def review():
  r = range(64695, 64720)
  review_scores = 0
  counter = 0
  for i in r:
    #print(column_data[i])
    temp = TextBlob(column_data[i])
    sentiment = temp.sentiment.polarity
    review_scores += sentiment
    counter += 1
  #print(counter)
  return review_scores/counter


print(f'Expected : {review()} ')
actual = unique_numbers['14636']
print(f'Actual : {actual}')

#print moview review in data set
#REMEMBER TO ACCOUNT FOR OFFSET IN RANGE CALCULATION
#if using gsheet line numbers:
#review = (start, end)
#range = (start - 2, end - 1 )
#29590:(2, 26)        range(0,25)
#5416:(6013, 6031)    range(6011, 6030)
def text():
  r = range(6011, 6030)
  for i in r:
    #print(html_id[i])
    print(f' line {i+2}: {column_data[i]}')

text()

review1_1 =  TextBlob(column_data[0])
#polarity value will be witin the range of  [-1, 1]
# -1 = negative sentiment
# +1 = positive sentiment

sentiment = review1_1.sentiment.polarity
print(review1_1)
print(sentiment)
#print(type(sentiment))


#  0.175 : on the positive side, but closer to neutral

#Reviews are broken down approxiamtely by sentences.
#review() takes each sentence and applies TextBlob's polarity score to it and returns the average polarity score.
def review1():
  r = range(0, 25)
  review1_scores = 0
  counter = 0
  for i in r:
    temp = TextBlob(column_data[i])
    sentiment = temp.sentiment.polarity
    review1_scores += sentiment
    counter += 1
  return review1_scores/counter

def review2():
  r = range(25, 64)
  review1_scores = 0
  counter = 0
  for i in r:
    temp = TextBlob(column_data[i])
    sentiment = temp.sentiment.polarity
    review1_scores += sentiment
    counter += 1
  return review1_scores/counter

def review3():
  r = range(64, 83)
  review1_scores = 0
  counter = 0
  for i in r:
    temp = TextBlob(column_data[i])
    sentiment = temp.sentiment.polarity
    review1_scores += sentiment
    counter += 1
  return review1_scores/counter

print(review1())  #0.04013961038961039
print(review2())  #0.0635927762713477
print(review3())  #0.1215154363180679

#TESTING, CAN IGNORE
def temp():
  for i in range(0, 100):
    print(f'line {i+2} : {html_id[i]} {column_data[i]}')

#temp()
#2 line off set
#removes header line
#gsheet starts at 1

#column_id:[String] = review sentence
#html_id:List[String] = reiview's unique identifier
#unique_numbers: Dict{html_id:float} = maps unique review tags to floats representing polarity

#create new dict dedicated polarity values
col_3_keys = worksheet.col_values(3)
col_3_keys = [val for val in col_3_keys if val.isdigit()]

expected_pol_dict = dict(OrderedDict.fromkeys(col_3_keys))
actual_pol_dict = dict(OrderedDict.fromkeys(col_3_keys))

#list for col 6 vals(polarity)
col_6_vals = worksheet.col_values(6)[1:]
#print(col_6_vals[0])

def mapPolarityExpected():
  col6counter = 0
  for tag in html_id:
    expected_pol_dict[tag] = col_6_vals[col6counter]
    col6counter += 1
  return expected_pol_dict

def mapPolarityActual():
  for key , value in unique_numbers.items():
    if value < 0.0:
      actual_pol_dict[key] = "neg"
    else:
      actual_pol_dict[key] = "pos"


mapPolarityExpected()
mapPolarityActual()

def getAccuracy():
  expectedResults = expected_pol_dict
  actualResults = actual_pol_dict
  print(expectedResults)
  print(actualResults)
  correct = 0
  total = 2000
  for key in unique_numbers.keys():
    if expectedResults[key] == actualResults[key]:
      correct += 1
  return (correct/total) * 100

getAccuracy()